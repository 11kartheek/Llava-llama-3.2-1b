# Llava-llama
# LLaVA 1.5: Training on 150k Dataset

## Overview
This repository explores the LLaVA 1.5 model, a state-of-the-art architecture designed for various natural language processing tasks. This project involves training LLaVA 1.5 on a dataset of 150,000 samples to evaluate its performance and capabilities.

## How LLaVA 1.5 Works
### explain architecture mlp with llava and qlora training

training_script https://github.com/11kartheek/Llava-qwen/blob/main/final_training.ipynb
inference_script https://github.com/11kartheek/Llava-qwen/blob/main/inference.ipynb
app_inference_script https://github.com/11kartheek/Llava-qwen/blob/main/app_inference.ipynb

## Dataset
- **Size**: 150,000 samples
- **Format**: [JSON]
- **Source**: [Link to the dataset or describe how to obtain it.](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)
- **Preprocessing**: [to be added]

## Base Model
The base model used for LLaVA 1.5 can be found here: [Link to Base Model on Hugging Face](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)
## base vision model
clip link

training logs snapshot

## Hugging Face Space
Explore the model in action and its capabilities on Hugging Face Spaces: [LLaVA 1.5 Space](https://huggingface.co/spaces/Kartheekb7/llava_chat)

